{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런 모듈 구조 Estimator fit() predict()\n",
    "\n",
    "- 분류(classfier)\n",
    "    - DecisionTreeClassifier\n",
    "    - RandomForestClassifier\n",
    "    - GradientBoostingClassifier\n",
    "    - GaussinNB\n",
    "    - SVC\n",
    "- 회귀(regressor)\n",
    "    - LinearRegression\n",
    "    - Rdige\n",
    "    - Lasso\n",
    "    - RandomForestRegressor\n",
    "    - GradientBoostingRegressor\n",
    "    \n",
    "### 사이킷런 주요 모듈\n",
    "- 예제 데이터 : sklearn.dataset\n",
    "- 데이터 분류,검증,파라미터튜닝 : sklearn.model_selection\n",
    "- 피처처리 : sklearn.\n",
    "    - preprocession : 전처리에 필요한 가공(인코딩,정규화,스케일링)\n",
    "    - feature_selection : 알고리즘에 큰 영향을 미치는 피처를 우선순위로 선택하는 작업을 수행 기능\n",
    "    - feature_extraction : 벡터화된 피처를 추출하는데 사용(이미지)\n",
    "        -feature_extraction.text\n",
    "        -feature_extraction.image\n",
    "- 피처처리 - 차원축소 : sklearn.decomposition  \n",
    "- 평가 : sklearn.metrics\n",
    "- 유틸리티 : sklearn.pipeline \n",
    "    - 피처처리등의 변환과 학습, 예측등을 묶어서 실행할 수 있는 유틸리티\n",
    "    \n",
    "- ML 알고리즘  : sklearn.\n",
    "    - ensemble : 앙상블 알고리즘 - 랜덤포레슽, 에이다부스트, 그래디언트부스팅등을 제공\n",
    "    - linear_model : 선형회귀, 리지,라쏘,로지스틱회귀 등\n",
    "    - naive_bayes : 가우시안 NB, 다항분포 NB\n",
    "    - neighbors : 최근접 이웃 알고리즘 K-NN 등\n",
    "    - svm : 서포트벡터머신알고리즘\n",
    "    - tree : 의사결정트리 알고리즘등\n",
    "    - cluster : 비지도 클러스터링 알고리즘 제공 K-means, 계층형, DBSCAN 등\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습/테스트 데이터 셋 분리 - train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # 내장 데이터 셋\n",
    "from sklearn.tree import DecisionTreeClassifier # 결정트리 모델(트리 알고리즘 카테고리)\n",
    "from sklearn.model_selection import train_test_split # 학습데이터와 테스트 데이터 분리 함수\n",
    "from sklearn.metrics import accuracy_score #평가 - 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "dt_clf.fit(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 셋으로 예측 수행\n",
    "pred = dt_clf.predict(train_data)  # 학습데이터와 예측데이터가 같으면 절때 안됨\n",
    "print(\"예측 정확도 : \",accuracy_score(train_label,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 데이터 내에서 학습데이터와 테스트 데이틀 분리해야 함\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.3, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "pred = dt_clf.predict(X_test)  # 학습데이터와 예측데이터가 같으면 절때 안됨\n",
    "print(\"예측 정확도 : \",accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_df = df.iloc[:,:-1]\n",
    "tgt_df = df.iloc[:,-1]\n",
    "X_train,X_test,y_train,y_test = train_test_split(ftr_df,tgt_df,test_size=0.3, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame,\n",
       " pandas.core.frame.DataFrame,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train),type(X_test),type(y_train),type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "pred = dt_clf.predict(X_test)  # 학습데이터와 예측데이터가 같으면 절때 안됨\n",
    "print(\"예측 정확도 : \",accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # 내장 데이터 셋\n",
    "from sklearn.tree import DecisionTreeClassifier # 결정트리 모델(트리 알고리즘 카테고리)\n",
    "from sklearn.model_selection import train_test_split # 학습데이터와 테스트 데이터 분리 함수\n",
    "from sklearn.metrics import accuracy_score #평가 - 정확도\n",
    "from sklearn.model_selection import KFold #교차검증 클래스\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 5개의 폴드 세트로 분리하는 KFold 객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "\n",
    "\n",
    "features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000001CB62B13580>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold.split(feautres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "검증 정확도 :  1.0\n",
      "학습데이터 크기 :  120 테스트데이터 크기 : 30\n",
      "검증세트 인덱스 :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "2\n",
      "검증 정확도 :  0.9667\n",
      "학습데이터 크기 :  120 테스트데이터 크기 : 30\n",
      "검증세트 인덱스 :  [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "3\n",
      "검증 정확도 :  0.8667\n",
      "학습데이터 크기 :  120 테스트데이터 크기 : 30\n",
      "검증세트 인덱스 :  [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "4\n",
      "검증 정확도 :  0.9333\n",
      "학습데이터 크기 :  120 테스트데이터 크기 : 30\n",
      "검증세트 인덱스 :  [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "5\n",
      "검증 정확도 :  0.7333\n",
      "학습데이터 크기 :  120 테스트데이터 크기 : 30\n",
      "검증세트 인덱스 :  [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "## 각 학습마다 검증정확도를 담을 리스트 객체\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(feautres) :  ## 실제 값이 아닌 index 반환\n",
    "    \n",
    "    ## 분할해서 반환된 index를 이용해서 학습용, 검증용 데이터 추출\n",
    "    X_train, X_val = feautres[train_index], feautres[test_index]\n",
    "    y_train, y_val = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred = dt_clf.predict(X_val)\n",
    "    \n",
    "    n_iter += 1\n",
    "    \n",
    "    ## 반복시 마다 정확도 측정, 데이터 인덱스 확인\n",
    "    accuracy = np.around(accuracy_score(y_val,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_val.shape[0]\n",
    "    print(n_iter)\n",
    "    print(\"검증 정확도 : \",accuracy)\n",
    "    print(\"학습데이터 크기 : \", train_size, \"테스트데이터 크기 :\", test_size)\n",
    "    print(\"검증세트 인덱스 : \",test_index)\n",
    "     ## 정확도 저장\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stratified K 폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "print(iris_df.head())\n",
    "iris_df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "교차검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "교차검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "for train_index, test_indexs in kfold.split(iris_df) :\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_indexs]\n",
    "    \n",
    "    print('교차검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n',label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n',label_test.value_counts())\n",
    "    \n",
    "## k_fold는 간단하게 분할해버림  \n",
    "## 학습레이블에 없는 레이블이 검증레이블에 있다  - 분류는 레이블의 분포가 고르게 되어야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold  ## 레이블 분포를 고르게 맞춰주는 FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "교차검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "교차검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_iter =0\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']) : #X,y 모두 들어가야 함\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print('교차검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n',label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n',label_test.value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156) #결정 트리 분류 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "검증 정확도 :  0.98\n",
      "학습데이터 크기 :  100 테스트데이터 크기 : 50\n",
      "검증세트 인덱스 :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "2\n",
      "검증 정확도 :  0.94\n",
      "학습데이터 크기 :  100 테스트데이터 크기 : 50\n",
      "검증세트 인덱스 :  [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "3\n",
      "검증 정확도 :  0.98\n",
      "학습데이터 크기 :  100 테스트데이터 크기 : 50\n",
      "검증세트 인덱스 :  [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "###  StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "## 각 학습마다 검증정확도를 담을 리스트 객체\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(feautres,label) :  ## 실제 값이 아닌 index 반환\n",
    "    \n",
    "    ## 분할해서 반환된 index를 이용해서 학습용, 검증용 데이터 추출\n",
    "    X_train, X_val = feautres[train_index], feautres[test_index]\n",
    "    y_train, y_val = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred = dt_clf.predict(X_val)\n",
    "    \n",
    "    n_iter += 1\n",
    "    \n",
    "    ## 반복시 마다 정확도 측정, 데이터 인덱스 확인\n",
    "    accuracy = np.around(accuracy_score(y_val,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_val.shape[0]\n",
    "    print(n_iter)\n",
    "    print(\"검증 정확도 : \",accuracy)\n",
    "    print(\"학습데이터 크기 : \", train_size, \"테스트데이터 크기 :\", test_size)\n",
    "    print(\"검증세트 인덱스 : \",test_index)\n",
    "     ## 정확도 저장\n",
    "    cv_accuracy.append(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cross_val_score( )  - cv에 설정된 숫자 만큼 학습 예측 검증을 진행 해 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score , cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data=iris_data.data\n",
    "label = iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
      "평균 검증 정확도 :  0.9667\n"
     ]
    }
   ],
   "source": [
    "# cross_val_score() - 성증지표는 정확도(accuracy), 교차검증세트 - 3개\n",
    "## 윗쪽 for문을 함수로 진행\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "\n",
    "print('교차 검증별 정확도 : ',np.round(scores,4))\n",
    "print('평균 검증 정확도 : ',np.round(np.mean(scores),4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GridSearchCV -  모델의 파라미터를 테스트 해 보고 싶을 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터를 로딩하고 학습데이타와 테스트 데이터 분리\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
    "                                                    test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변경해보고 싶은 파라미터를 넘겨줘야 함 -dict 형태\n",
    "## key : []\n",
    "## {파라미터명 : [변경값,변경값1], 파라미터명2 : [변경값,변경값2]}\n",
    "parameters = {'max_depth':[1,2,3],'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 3으로 분할(cv) , param_grid의 값을 이용해 파라미터들을 변경해서 학습,검증 진행\n",
    "grid_tree = GridSearchCV(dtree, param_grid=parameters, cv=3,return_train_score=True,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 학습 데이터를 grid_tree 에 설정되어 있는 인수로 학습/검증\n",
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습/검증된 결과를 확인 -> 객체.cv_results_  속성에 딕셔너리 형태로 저장되어 있음\n",
    "scores_df = pd.DataFrame(grid_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_max_depth', 'param_min_samples_split', 'params',\n",
       "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'mean_test_score', 'std_test_score', 'rank_test_score',\n",
       "       'split0_train_score', 'split1_train_score', 'split2_train_score',\n",
       "       'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 파라미터 :  {'max_depth': 3, 'min_samples_split': 2}\n",
      "최고 정확도: 0.9750\n"
     ]
    }
   ],
   "source": [
    "print('최적 파라미터 : ', grid_tree.best_params_) #최적 파라미터\n",
    "print('최고 정확도: {0:.4f}'.format(grid_tree.best_score_)) # 최고 정확도 - 1등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "## GridSearchCV는 refit 옵션으로 최적의 파라미터로 재학습된 estimator 반환\n",
    "# estimator = grid_tree.best_estimator_\n",
    "# pred = estimator.predict(X_test)\n",
    "pred = grid_tree.predict(X_test)\n",
    "print('테스트 데이터 정확도 : {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
